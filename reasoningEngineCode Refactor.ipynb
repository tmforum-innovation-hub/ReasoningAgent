{
  "cells": [
    {
      "cell_type": "code",
      "id": "cMzVK6bZ5gOQs7L9IxAjSQIf",
      "metadata": {
        "tags": [],
        "id": "cMzVK6bZ5gOQs7L9IxAjSQIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555939826,
          "user_tz": -330,
          "elapsed": 26707,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "daf40dad-f200-4bee-e5d6-897b01fbbbf3"
      },
      "source": [
        "%pip install google-cloud-discoveryengine --upgrade --user\n",
        "%pip install --upgrade google-auth\n",
        "!pip install --upgrade --quiet \\\n",
        "    google-cloud-aiplatform==1.51.0 \\\n",
        "    langchain==0.1.20 \\\n",
        "    langchain-google-vertexai==1.0.3 \\\n",
        "    cloudpickle==3.0.0 \\\n",
        "    pydantic==2.7.1 \\\n",
        "    langchain_google_community \\\n",
        "    google-cloud-discoveryengine \\\n",
        "    google-api-python-client \\\n",
        "    requests \\\n",
        "    python-dotenv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-discoveryengine in /root/.local/lib/python3.10/site-packages (0.11.11)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (2.19.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (2.29.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-discoveryengine) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.32.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2024.2.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.29.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## All the Required imports\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import discoveryengine_v1 as discoveryengine\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from vertexai.preview import reasoning_engines\n",
        "from googleapiclient import discovery\n",
        "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from operator import itemgetter\n",
        "from typing import List\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import BaseMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    ConfigurableFieldSpec,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core import prompts\n",
        "from langchain_core import agents\n",
        "from langchain.agents.format_scratchpad import (\n",
        "    format_to_openai_function_messages\n",
        ")\n",
        "\n",
        "import google.auth\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import vertexai\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "jHG8M_Zs5e58",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555943443,
          "user_tz": -330,
          "elapsed": 3620,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "jHG8M_Zs5e58",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Environment Variables needs to be set explicitly based on the env(dev/SIT)\n",
        "# !export PROJECT_ID=\"enterprise-search-gen-ai\"\n",
        "# !export LOCATION=\"global\"\n",
        "# !export STAGING_BUCKET=\"gs://agent-test-srini\"\n",
        "# !export DATA_STORE_ID_PDF=\"tmf-metadata-layout-p_1715009821486\"\n",
        "# !export DATA_STORE_ID_WEB=\"tmf-public_1692445422672\""
      ],
      "metadata": {
        "id": "eaI4Y-5L9URN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716545086044,
          "user_tz": -330,
          "elapsed": 670,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "eaI4Y-5L9URN",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "_=load_dotenv(find_dotenv())\n",
        "credentials, _ = google.auth.default()\n",
        "request = google.auth.transport.requests.Request()\n",
        "credentials.refresh(request)\n",
        "PROJECT_ID = os.getenv('PROJECT_ID')\n",
        "LOCATION = os.getenv('LOCATION')\n",
        "STAGING_BUCKET = os.getenv('STAGING_BUCKET')\n",
        "DATA_STORE_ID_PDF = os.getenv('DATA_STORE_ID_PDF')\n",
        "DATA_STORE_ID_WEB = os.getenv('DATA_STORE_ID_WEB')\n",
        "AUTH_TOKEN = credentials.token"
      ],
      "metadata": {
        "id": "LR221i4c8j3Y",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555946875,
          "user_tz": -330,
          "elapsed": 706,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "LR221i4c8j3Y",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "}\n",
        "\n",
        "# model =\"gemini-1.5-pro-latest\"\n",
        "model = \"gemini-1.5-pro-preview-0409\"\n",
        "\n",
        "# model configuration\n",
        "model_kwargs = {\n",
        "    # temperature (float): The sampling temperature controls the degree of\n",
        "    # randomness in token selection.\n",
        "    \"temperature\": 0.28,\n",
        "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
        "    # text output from one prompt.\n",
        "    \"max_output_tokens\": 1000,\n",
        "    # top_p (float): Tokens are selected from most probable to least until\n",
        "    # the sum of their probabilities equals the top-p value.\n",
        "    \"top_p\": 0.95,\n",
        "    # top_k (int): The next token is selected from among the top-k most\n",
        "    # probable tokens.\n",
        "    \"top_k\": 40,\n",
        "    \"safety_settings\": safety_settings,\n",
        "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
        "    # settings to use for generating content.\\\n",
        "}"
      ],
      "metadata": {
        "id": "YPdRSlCWMpnO",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555948897,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "YPdRSlCWMpnO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This prompt template needs to be changed\n",
        "\n",
        "prompt = {\n",
        "    \"history\": lambda x: x[\"history\"],\n",
        "    \"input\": lambda x: x[\"input\"],\n",
        "    \"agent_scratchpad\": (\n",
        "        lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
        "    ),\n",
        "} | prompts.ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    Please use the appropriate tool based on the user's input.\n",
        "    Call search_web_and_pdf to answer all the user questions EXCEPT code generation requests.\n",
        "    Call swagger_gen to generate code for the spec in the url and respond as in the example below.\n",
        "    Example:\n",
        "    I have generated server code in Python Flask for the spec in the url http://petstore.swagger.io/v2/swagger.json.\n",
        "    You can download it from this link: 'https://generator.swagger.io/api/gen/download/4ad93713-be44-4514-8344-493bb44d5b97'\n",
        "    \"\"\"),\n",
        "    (\"placeholder\", \"{history}\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "U5t-pzSxOcgZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555953734,
          "user_tz": -330,
          "elapsed": 730,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "U5t-pzSxOcgZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=PROJECT_ID, location='us-central1', staging_bucket=STAGING_BUCKET)"
      ],
      "metadata": {
        "id": "MDLeGUj-O-RI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555957258,
          "user_tz": -330,
          "elapsed": 641,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "MDLeGUj-O-RI",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gcp_websearch(\n",
        "    query_input: str,\n",
        "    auth_token: str,\n",
        "    project_id:str,\n",
        "    location_id: str,\n",
        "    datastore_id: str,\n",
        "    llm_model_version:str,\n",
        "    summary_result_size:int\n",
        "):\n",
        "\n",
        "    \"\"\"Looks up for things in the web related to tmf forum\"\"\"\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    END_POINT_URL = f'https://discoveryengine.googleapis.com/v1alpha/projects/{project_id}/locations/{location_id}/collections/default_collection/dataStores/{datastore_id}/conversations/-:converse'\n",
        "    headers = {'Content-type': 'application/json',\n",
        "               'Accept': 'text/plain',\n",
        "               'Authorization':f'Bearer {auth_token}'}\n",
        "    data = {\n",
        "      \"query\": {\n",
        "        \"input\": query_input\n",
        "        },\n",
        "      \"summarySpec\": {\n",
        "        \"summaryResultCount\": summary_result_size,\n",
        "        # \"modelPromptSpec\": {\n",
        "        #   \"preamble\": \"Given the conversation between a user and a helpful assistant and some search results, create a final answer for the assistant. The answer should use all relevant information from the search results, not introduce any additional information, and use exactly the same words as the search results when possible. The assistant's answer should be no more than 20 sentences. The user is an expert who has an in-depth understanding of the subject matter. The assistant should answer in a technical manner that uses specialized knowledge and terminology when it helps answer the query.\"\n",
        "        # },\n",
        "        \"modelSpec\": {\n",
        "          \"version\": llm_model_version\n",
        "        },\n",
        "        \"ignoreAdversarialQuery\": True,\n",
        "        \"includeCitations\": True\n",
        "      }\n",
        "    }\n",
        "\n",
        "    r = requests.post(END_POINT_URL, data=json.dumps(data), headers=headers)\n",
        "    return r.json()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GdwPoPfO95na",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555963518,
          "user_tz": -330,
          "elapsed": 644,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "GdwPoPfO95na",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gcp_pdfsearch(\n",
        "    query_input: str,\n",
        "    auth_token: str,\n",
        "    project_id: str,\n",
        "    location_id: str,\n",
        "    datastore_id: str,\n",
        "    page_size: int,\n",
        "    llm_model_version: str,\n",
        ")-> str:\n",
        "\n",
        "\n",
        "    \"\"\"Looks up for things in pdf document stored  related to tmf forum\"\"\"\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "\n",
        "    END_POINT_URL = f'https://discoveryengine.googleapis.com/v1alpha/projects/{project_id}/locations/{location_id}/collections/default_collection/dataStores/{datastore_id}/servingConfigs/default_search:search'\n",
        "    headers = {'Content-type': 'application/json',\n",
        "               'Accept': 'text/plain',\n",
        "               'Authorization':f'Bearer {auth_token}'}\n",
        "    data = {\n",
        "      \"query\": query_input,\n",
        "      \"pageSize\": page_size,\n",
        "      \"queryExpansionSpec\": {\n",
        "        \"condition\": \"AUTO\"\n",
        "      },\n",
        "      \"spellCorrectionSpec\": {\n",
        "        \"mode\": \"AUTO\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "    r = requests.post(END_POINT_URL, data=json.dumps(data), headers=headers)\n",
        "    return r.json()\n",
        "\n"
      ],
      "metadata": {
        "id": "xrwLkqFA_lD8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555968005,
          "user_tz": -330,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "xrwLkqFA_lD8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web_and_pdf(\n",
        "    query_str: str):\n",
        "\n",
        "    \"\"\"This is the function to call to answer all the user questions EXCEPT code generation requests.\"\"\"\n",
        "\n",
        "    import requests\n",
        "    from dotenv import load_dotenv, find_dotenv\n",
        "    import os\n",
        "    # _=load_dotenv(find_dotenv())\n",
        "\n",
        "    PROJECT_ID = \"enterprise-search-gen-ai\"\n",
        "    LOCATION_ID = \"global\"\n",
        "    DATA_STORE_ID_PDF = \"tmf-metadata-layout-p_1715009821486\" # PDF\n",
        "    DATA_STORE_ID_WEB = \"tmf-public_1692445422672\" # WEB\n",
        "\n",
        "    query = query_str\n",
        "\n",
        "    vertexai.init(project=PROJECT_ID, location='us-central1')\n",
        "\n",
        "    from google.oauth2 import service_account\n",
        "    from vertexai.generative_models import (\n",
        "      GenerativeModel,\n",
        "    )\n",
        "\n",
        "    import google.auth\n",
        "    credentials, _ = google.auth.default()\n",
        "    model = GenerativeModel(\"gemini-1.5-flash-preview-0514\")\n",
        "    request = google.auth.transport.requests.Request() # User is handling it, user token will come, if the service account token will come.\n",
        "    credentials.refresh(request)\n",
        "\n",
        "\n",
        "\n",
        "    pdf_response = gcp_pdfsearch(\n",
        "                  query_input=query_str,\n",
        "                  auth_token=credentials.token,\n",
        "                  project_id=PROJECT_ID,\n",
        "                  location_id=LOCATION_ID,\n",
        "                  datastore_id=DATA_STORE_ID_PDF,\n",
        "                  page_size= 10,\n",
        "                  llm_model_version=\"gemini-1.0-pro-002/answer_gen/v1\"\n",
        "                )\n",
        "\n",
        "    web_response = gcp_websearch(\n",
        "                  query_input=query_str,\n",
        "                  auth_token=credentials.token,\n",
        "                  project_id=PROJECT_ID,\n",
        "                  location_id=LOCATION_ID,\n",
        "                  datastore_id=DATA_STORE_ID_WEB,\n",
        "                  summary_result_size= 5,\n",
        "                  llm_model_version=\"gemini-1.0-pro-002/answer_gen/v1\"\n",
        "                )\n",
        "\n",
        "\n",
        "    # return response1, response2\n",
        "    # print(response1)\n",
        "\n",
        "    # nothing_found = True\n",
        "\n",
        "    # summary_query = \"\"\"You are an expert TM Forum assistant talking to a technically savvy user.\n",
        "    # Please answer the user query from all the relevant information conatained in any part of the contexts.\"\"\" + query + \"\\n\\n\"\n",
        "\n",
        "    # # Provide your response as either itemized lists as bullets or running text in paragraphs as appropriate.\"\"\" + \"\\n\\n\" + \"User Query: \" + query + \"\\n\\n\"\n",
        "    # if \"cannot be answered\" not in response1.summary.summary_text:\n",
        "    #     summary_query = summary_query + \"Context: \" + response1.summary.summary_text + \"\\n\\n\"\n",
        "    #     nothing_found = False\n",
        "    # if \"cannot be answered\" not in response2.summary.summary_text:\n",
        "    #     summary_query = summary_query + \"Context: \" + response2.summary.summary_text + \"\\n\\n\"\n",
        "    #     nothing_found = False\n",
        "\n",
        "    # if not nothing_found:\n",
        "    #     summary = model.generate_content(summary_query)\n",
        "    # else:\n",
        "    #     summary = \"I am sorry, this question cannot be answered from information I have.  Please let me know if I can help you in finding any other TM Forum information\"\n",
        "    consolidated_responses = [pdf_response, web_response]\n",
        "    return consolidated_responses"
      ],
      "metadata": {
        "id": "VbUoeYtjAMuf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555972216,
          "user_tz": -330,
          "elapsed": 641,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "VbUoeYtjAMuf",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swagger_gen(\n",
        "    text: str,\n",
        "):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Generates Server/ Client code using Swagger Code Generator Cloud Function for the given text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): The text to be sent in the request body.\n",
        "    - url (str): The endpoint URL.\n",
        "\n",
        "    Returns:\n",
        "    - dict: The JSON response from the server.\n",
        "    \"\"\"\n",
        "    import requests\n",
        "    import json\n",
        "    import google.auth.transport.requests\n",
        "    import google.oauth2.id_token\n",
        "\n",
        "\n",
        "    # credentials, _ = google.auth.default()\n",
        "    auth_request = google.auth.transport.requests.Request() # User is handling it, user token will come, if the service account token will come.\n",
        "    url= \"https://us-central1-enterprise-search-gen-ai.cloudfunctions.net/swagger-code-generator-1\"\n",
        "    id_token = google.oauth2.id_token.fetch_id_token(auth_request, url)\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"bearer {id_token}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"text\": text\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data, timeout=70)\n",
        "\n",
        "    return response.json()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yUzYJOtFDPBM",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555980433,
          "user_tz": -330,
          "elapsed": 742,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "yUzYJOtFDPBM",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = swagger_gen(\"Can you give me the code for Product catalogue management version 4?\")\n",
        "res"
      ],
      "metadata": {
        "id": "dfGvh_-mfnwn"
      },
      "id": "dfGvh_-mfnwn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
        "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
        "\n",
        "    messages: List[BaseMessage] = Field(default_factory=list)\n",
        "\n",
        "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
        "        \"\"\"Add a list of messages to the store\"\"\"\n",
        "        self.messages.extend(messages)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "\n",
        "# Here we use a global variable to store the chat message history.\n",
        "# This will make it easier to inspect it to see the underlying results.\n",
        "store = {}\n",
        "\n",
        "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryHistory()\n",
        "    return store[session_id]\n"
      ],
      "metadata": {
        "id": "14dy5k2MOlyb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716555983859,
          "user_tz": -330,
          "elapsed": 706,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "14dy5k2MOlyb",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DISPLAY_NAME = \"TMFMultiChatApp\"\n",
        "\n",
        "remote_app = reasoning_engines.ReasoningEngine.create(\n",
        "    reasoning_engines.LangchainAgent(\n",
        "        model=model,\n",
        "        tools=[search_web_and_pdf,swagger_gen],\n",
        "        model_kwargs=model_kwargs,\n",
        "        agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
        "        chat_history=get_by_session_id\n",
        "    ),\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform==1.51.0\",\n",
        "        \"langchain==0.1.20\",\n",
        "        \"langchain-google-vertexai==1.0.3\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.1\",\n",
        "        \"requests\",\n",
        "        \"google-cloud-discoveryengine\",\n",
        "        \"google-auth\",\n",
        "        \"python-dotenv\"\n",
        "    ],\n",
        "    display_name=DISPLAY_NAME,\n",
        ")\n",
        "remote_app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jvLxDvqN9n9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716556167461,
          "user_tz": -330,
          "elapsed": 180345,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "c724f79d-0e99-4983-cad2-d231d37b9f28"
      },
      "id": "7jvLxDvqN9n9",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.reasoning_engines._reasoning_engines:Using bucket agent-test-srini\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://agent-test-srini/reasoning_engine/reasoning_engine.pkl\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://agent-test-srini/reasoning_engine/requirements.txt\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating in-memory tarfile of extra_packages\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://agent-test-srini/reasoning_engine/dependencies.tar.gz\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating ReasoningEngine\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Create ReasoningEngine backing LRO: projects/982845833565/locations/us-central1/reasoningEngines/6584192286471487488/operations/181261398146285568\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:ReasoningEngine created. Resource name: projects/982845833565/locations/us-central1/reasoningEngines/6584192286471487488\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:To use this ReasoningEngine in another session:\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/982845833565/locations/us-central1/reasoningEngines/6584192286471487488')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<vertexai.reasoning_engines._reasoning_engines.ReasoningEngine object at 0x7dbb71155990> \n",
              "resource name: projects/982845833565/locations/us-central1/reasoningEngines/6584192286471487488"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "try:\n",
        "  res = remote_app.query(input=\"Can you give me the code for Product catalogue management version 4?\", config={\"configurable\": {\"session_id\": \"game\"}})\n",
        "  pprint.pprint(res)\n",
        "except Exception as e:\n",
        "  pprint.pprint(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMuGwszPO6fz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1716556188228,
          "user_tz": -330,
          "elapsed": 20768,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "83e937eb-e1ee-4b70-bb0f-80be04fac768"
      },
      "id": "UMuGwszPO6fz",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'history': [],\n",
            " 'input': 'Can you give me the code for Product catalogue management version '\n",
            "          '4?',\n",
            " 'intermediate_steps': [[{'id': ['langchain',\n",
            "                                 'schema',\n",
            "                                 'agent',\n",
            "                                 'ToolAgentAction'],\n",
            "                          'kwargs': {'log': '\\n'\n",
            "                                            'Invoking: `swagger_gen` with '\n",
            "                                            \"`{'text': 'Product Catalog \"\n",
            "                                            \"Management API V4'}`\\n\"\n",
            "                                            '\\n'\n",
            "                                            '\\n',\n",
            "                                     'message_log': [{'id': ['langchain',\n",
            "                                                             'schema',\n",
            "                                                             'messages',\n",
            "                                                             'AIMessageChunk'],\n",
            "                                                      'kwargs': {'additional_kwargs': {'function_call': {'arguments': '{\"text\": '\n",
            "                                                                                                                      '\"Product '\n",
            "                                                                                                                      'Catalog '\n",
            "                                                                                                                      'Management '\n",
            "                                                                                                                      'API '\n",
            "                                                                                                                      'V4\"}',\n",
            "                                                                                                         'name': 'swagger_gen'}},\n",
            "                                                                 'content': '',\n",
            "                                                                 'id': 'run-d6c1227f-198f-4ff0-939d-3b2e61d73643',\n",
            "                                                                 'invalid_tool_calls': [],\n",
            "                                                                 'response_metadata': {'citation_metadata': None,\n",
            "                                                                                       'is_blocked': False,\n",
            "                                                                                       'safety_ratings': [{'blocked': False,\n",
            "                                                                                                           'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
            "                                                                                                           'probability_label': 'NEGLIGIBLE'},\n",
            "                                                                                                          {'blocked': False,\n",
            "                                                                                                           'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
            "                                                                                                           'probability_label': 'NEGLIGIBLE'},\n",
            "                                                                                                          {'blocked': False,\n",
            "                                                                                                           'category': 'HARM_CATEGORY_HARASSMENT',\n",
            "                                                                                                           'probability_label': 'NEGLIGIBLE'},\n",
            "                                                                                                          {'blocked': False,\n",
            "                                                                                                           'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
            "                                                                                                           'probability_label': 'NEGLIGIBLE'}],\n",
            "                                                                                       'usage_metadata': {'candidates_token_count': 10.0,\n",
            "                                                                                                          'prompt_token_count': 132.0,\n",
            "                                                                                                          'total_token_count': 142.0}},\n",
            "                                                                 'tool_call_chunks': [{'args': '{\"text\": '\n",
            "                                                                                               '\"Product '\n",
            "                                                                                               'Catalog '\n",
            "                                                                                               'Management '\n",
            "                                                                                               'API '\n",
            "                                                                                               'V4\"}',\n",
            "                                                                                       'id': 'f4c66c7f-c766-4a8f-a85e-6e9a3d154944',\n",
            "                                                                                       'index': None,\n",
            "                                                                                       'name': 'swagger_gen'}],\n",
            "                                                                 'tool_calls': [{'args': {'text': 'Product '\n",
            "                                                                                                  'Catalog '\n",
            "                                                                                                  'Management '\n",
            "                                                                                                  'API '\n",
            "                                                                                                  'V4'},\n",
            "                                                                                 'id': 'f4c66c7f-c766-4a8f-a85e-6e9a3d154944',\n",
            "                                                                                 'name': 'swagger_gen'}],\n",
            "                                                                 'type': 'AIMessageChunk'},\n",
            "                                                      'lc': 1.0,\n",
            "                                                      'type': 'constructor'}],\n",
            "                                     'tool': 'swagger_gen',\n",
            "                                     'tool_call_id': 'f4c66c7f-c766-4a8f-a85e-6e9a3d154944',\n",
            "                                     'tool_input': {'text': 'Product Catalog '\n",
            "                                                            'Management API '\n",
            "                                                            'V4'},\n",
            "                                     'type': 'AgentActionMessageLog'},\n",
            "                          'lc': 1.0,\n",
            "                          'type': 'constructor'},\n",
            "                         {'result': 'https://storage.cloud.google.com/tfm-ai-assistant-codegen-dev/generatedCodeFile/TMF620_Product_Catalog_Management_API_v4_1716556182990.zip'}]],\n",
            " 'output': 'The server returned: {\"content\": \"{\\\\\"result\\\\\": '\n",
            "           '\\\\\"https://storage.cloud.google.com/tfm-ai-assistant-codegen-dev/generatedCodeFile/TMF620_Product_Catalog_Management_API_v4_1716556182990.zip\\\\\"}\"} \\n'\n",
            "           '\\n'\n",
            "           'You can download the generated code from: '\n",
            "           'https://storage.cloud.google.com/tfm-ai-assistant-codegen-dev/generatedCodeFile/TMF620_Product_Catalog_Management_API_v4_1716556182990.zip. \\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulk Queries Testing"
      ],
      "metadata": {
        "id": "0mxlQBq6trdz"
      },
      "id": "0mxlQBq6trdz"
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "import re\n",
        "import time\n",
        "\n",
        "from ratelimit import limits, sleep_and_retry\n",
        "\n",
        "# Define the rate limit (e.g., 1000 requests per minute)\n",
        "RATE_LIMIT = 5 # Number of requests\n",
        "RATE_PERIOD = 60  # Time period in seconds\n",
        "\n",
        "running_time = []\n",
        "# Decorator to apply rate limiting\n",
        "@sleep_and_retry\n",
        "@limits(calls=RATE_LIMIT, period=RATE_PERIOD)\n",
        "def query_reasoning_engine(query,reasoning_engine):\n",
        "    return reasoning_engine.query(input=query)\n",
        "\n",
        "\n",
        "def extract_pdf_references(data):\n",
        "    references = []\n",
        "    try:\n",
        "        # Regular expression to find references\n",
        "        reference_pattern = r'references {\\s*title: \"(.*?)\"\\s*document: \"(.*?)\"\\s*uri: \"(.*?)\"'\n",
        "        matches = re.findall(reference_pattern, data, re.DOTALL)\n",
        "\n",
        "        for match in matches:\n",
        "            title, document, uri = match\n",
        "            references.append({\n",
        "                \"title\": title,\n",
        "                \"document\": document,\n",
        "                \"uri\": uri\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return references\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_web_references(data):\n",
        "    links = []\n",
        "    try:\n",
        "        # Define the regular expression pattern\n",
        "        pattern = r'fields {\\n\\s+key: \\\"link\\\"\\n\\s+value {\\n\\s+string_value: \\\"(.*?)\\\"'\n",
        "\n",
        "        # Find all occurrences of the pattern\n",
        "        matches = re.findall(pattern, data, re.DOTALL)\n",
        "\n",
        "        # Store the matches in a separate list\n",
        "        links.extend(matches)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return links\n",
        "\n",
        "\n",
        "\n",
        "def answer_questions(\n",
        "    row, reasoning_engine, project_id: str, location: str, top_n: int = 5\n",
        ") -> None:\n",
        "    while True:\n",
        "        try:\n",
        "            start = time.time()\n",
        "            response = query_reasoning_engine(row[\"Query\"], reasoning_engine)\n",
        "            intermediate_steps = response['intermediate_steps'][0][1]\n",
        "\n",
        "            top5docs_pdf, top5docs_web = [], []\n",
        "\n",
        "            for pages in intermediate_steps:\n",
        "                try:\n",
        "                    references = extract_pdf_references(pages['repr'])\n",
        "                    if len(references) == 0:\n",
        "                        references = extract_web_references(pages['repr'])\n",
        "                        top5docs_web.append(references)\n",
        "                    else:\n",
        "                        top5docs_pdf.append(references)\n",
        "\n",
        "                    print(references)\n",
        "\n",
        "                except Exception as e:\n",
        "                    # print(f\"An error occurred: {e} for page {pages}\")\n",
        "                    continue\n",
        "\n",
        "            row[\"Top 5 Docs PDF\"] = top5docs_pdf\n",
        "            row[\"Top 5 Docs Web\"] = top5docs_web\n",
        "            row[\"Summary\"] = response['output']\n",
        "\n",
        "            end = time.time()\n",
        "            running_time.append(end - start)\n",
        "            print(f\"Time taken for query {row['Query']} is {end - start}\")\n",
        "\n",
        "            break  # Exit the loop if successful\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}. Retrying in 60 seconds...\")\n",
        "            time.sleep(60)  # Wait for 60 seconds before retrying"
      ],
      "metadata": {
        "id": "E5N8uR-pSCsq"
      },
      "id": "E5N8uR-pSCsq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-u5142aRt2kl"
      },
      "id": "-u5142aRt2kl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "prasadyashdeep2000 (May 24, 2024, 2:47:56â€¯PM)",
      "collapsed_sections": [
        "0mxlQBq6trdz"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}