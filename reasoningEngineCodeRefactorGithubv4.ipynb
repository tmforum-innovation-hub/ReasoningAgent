{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TM Forum AIVA - Resoning Engine based Agent"
      ],
      "metadata": {
        "id": "ymWZKqnVnJPK"
      },
      "id": "ymWZKqnVnJPK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "dC4T8eSWnQBG"
      },
      "id": "dC4T8eSWnQBG"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install google-cloud-discoveryengine --upgrade --user\n",
        "%pip install --upgrade google-auth\n",
        "!pip install --upgrade --quiet \\\n",
        "    google-cloud-aiplatform==1.51.0 \\\n",
        "    langchain==0.1.20 \\\n",
        "    langchain-google-vertexai==1.0.3 \\\n",
        "    cloudpickle==3.0.0 \\\n",
        "    pydantic==2.7.1 \\\n",
        "    langchain_google_community \\\n",
        "    google-cloud-discoveryengine \\\n",
        "    google-api-python-client \\\n",
        "    requests \\\n",
        "    ratelimit \\\n",
        "    python-dotenv"
      ],
      "metadata": {
        "id": "YB1978GInLIi"
      },
      "id": "YB1978GInLIi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## All the Required imports\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import discoveryengine_v1 as discoveryengine\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from vertexai.preview import reasoning_engines\n",
        "from googleapiclient import discovery\n",
        "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from operator import itemgetter\n",
        "from typing import List\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import BaseMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    ConfigurableFieldSpec,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core import prompts\n",
        "from langchain_core import agents\n",
        "from langchain.agents.format_scratchpad import (\n",
        "    format_to_openai_function_messages\n",
        ")\n",
        "\n",
        "import google.auth\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import vertexai\n",
        "import requests"
      ],
      "metadata": {
        "id": "002L3ZG9nWk1"
      },
      "id": "002L3ZG9nWk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment variables"
      ],
      "metadata": {
        "id": "-FFDGrkgnjuD"
      },
      "id": "-FFDGrkgnjuD"
    },
    {
      "cell_type": "code",
      "source": [
        "## Environment Variables needs to be set explicitly based on the env(dev/SIT)\n",
        "# !export PROJECT_ID=\"enterprise-search-gen-ai\"\n",
        "# !export SEARCH_APP_LOCATION=\"global\"\n",
        "# !export STAGING_BUCKET=\"gs://agent-test-srini\"\n",
        "# !export DATA_STORE_ID_PDF=\"tmf-metadata-layout-p_1715009821486\"\n",
        "# !export DATA_STORE_ID_WEB=\"tmf-public_1692445422672\"\n",
        "# !export AGENT_LOCATION=\"us-central1\""
      ],
      "metadata": {
        "id": "SkkFQvdXngVS"
      },
      "id": "SkkFQvdXngVS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "_ = load_dotenv(find_dotenv())\n",
        "credentials, _ = google.auth.default()\n",
        "request = google.auth.transport.requests.Request()\n",
        "credentials.refresh(request)\n",
        "AUTH_TOKEN = credentials.token\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID') if os.getenv('PROJECT_ID') else 'enterprise-search-gen-ai'\n",
        "\n",
        "SEARCH_APP_LOCATION = os.getenv('SEARCH_APP_LOCATION') if os.getenv('SEARCH_APP_LOCATION') else 'global'\n",
        "AGENT_LOCATION = os.getenv('AGENT_LOCATION') if os.getenv('AGENT_LOCATION') else 'us-central1'\n",
        "\n",
        "STAGING_BUCKET = os.getenv('STAGING_BUCKET') if os.getenv('STAGING_BUCKET') else 'gs://agent-test-srini'\n",
        "DATA_STORE_ID_PDF = os.getenv('DATA_STORE_ID_PDF') if os.getenv('DATA_STORE_ID_PDF') else \"tmf-metadata-layout-p_1715009821486\"\n",
        "DATA_STORE_ID_WEB = os.getenv('DATA_STORE_ID_WEB') if os.getenv('DATA_STORE_ID_WEB') else \"tmf-public_1692445422672\"\n",
        "CODE_GEN_CLOUD_FUNCTION_URL = os.getenv('CODE_GEN_CLOUD_FUNCTION_URL') if os.getenv('CODE_GEN_CLOUD_FUNCTION_URL') else \"https://us-central1-enterprise-search-gen-ai.cloudfunctions.net/swagger-code-generator-1\""
      ],
      "metadata": {
        "id": "kR8-rdPNnmkO"
      },
      "id": "kR8-rdPNnmkO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PROJECT_ID)\n",
        "print(SEARCH_APP_LOCATION)\n",
        "print(AGENT_LOCATION)\n",
        "print(STAGING_BUCKET)\n",
        "print(DATA_STORE_ID_PDF)\n",
        "print(DATA_STORE_ID_WEB)\n",
        "print(CODE_GEN_CLOUD_FUNCTION_URL)"
      ],
      "metadata": {
        "id": "s8YFLnrMnooH"
      },
      "id": "s8YFLnrMnooH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "}\n",
        "\n",
        "# model =\"gemini-1.5-pro-latest\"\n",
        "AGENT_LLM_MODEL = \"gemini-1.5-flash-001\" # \"gemini-1.5-pro\" # \"gemini-1.5-flash-preview-0514\" # \"gemini-1.5-pro-preview-0409\"\n",
        "\n",
        "# model configuration\n",
        "AGENT_LLM_MODEL_KWARGS = {\n",
        "    # temperature (float): The sampling temperature controls the degree of\n",
        "    # randomness in token selection.\n",
        "    \"temperature\": 0.28,\n",
        "    # max_output_tokens (int): The token limit determines the maximum amount of\n",
        "    # text output from one prompt.\n",
        "    \"max_output_tokens\": 1000,\n",
        "    # top_p (float): Tokens are selected from most probable to least until\n",
        "    # the sum of their probabilities equals the top-p value.\n",
        "    \"top_p\": 0.95,\n",
        "    # top_k (int): The next token is selected from among the top-k most\n",
        "    # probable tokens.\n",
        "    \"top_k\": 40,\n",
        "    \"safety_settings\": safety_settings,\n",
        "    # safety_settings (Dict[HarmCategory, HarmBlockThreshold]): The safety\n",
        "    # settings to use for generating content.\\\n",
        "}"
      ],
      "metadata": {
        "id": "TzsAf9j5nrAJ"
      },
      "id": "TzsAf9j5nrAJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex AI tools"
      ],
      "metadata": {
        "id": "_ur099Oznzsh"
      },
      "id": "_ur099Oznzsh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCP search datastore tool"
      ],
      "metadata": {
        "id": "tPJgPG8Rn5vM"
      },
      "id": "tPJgPG8Rn5vM"
    },
    {
      "cell_type": "code",
      "source": [
        "def search_data_store(\n",
        "    query_input: str,\n",
        "    auth_token: str,\n",
        "    project_id: str,\n",
        "    location_id: str,\n",
        "    datastore_id: str,\n",
        "    page_size: int,\n",
        "    llm_model_version: str,\n",
        "    ):\n",
        "#)-> str:\n",
        "\n",
        "\n",
        "    \"\"\"Looks up for things in pdf document stored  related to tmf forum\"\"\"\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    # @markdown ### API Parameters\n",
        "    asynchronous_mode = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "    # @markdown SAFETY_SPEC\n",
        "    safe_search = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "    # @markdown RELATED_QUESTION_SPEC\n",
        "    related_questions = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "    # @markdown QUERY_UNDERSTANDING_SPEC\n",
        "    disable_query_rephraser = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "    max_rephrase_steps = 1 # @param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "    # @markdown SEARCH_SPEC\n",
        "    max_return_results = 3 # @param {type:\"slider\", min:0, max:10, step:1}\n",
        "    search_filter = '' # @param {type: 'string'}\n",
        "\n",
        "    # @markdown ANSWER_GENERATION_SPEC\n",
        "    include_citations = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "    ignore_adversarial_query = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "    ignore_non_answer_seeking_query = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "    answer_gen_preamble = '' # @param {type:\"string\"}\n",
        "    answer_gen_language_code = '' # @param [\"en\", \"es\", \"jp\"] {allow-input: true}\n",
        "    # A couple options for the model: https://cloud.google.com/generative-ai-app-builder/docs/answer-generation-models\n",
        "    answer_gen_version = 'gemini-1.0-pro-002/answer_gen/v1' # @param [\"preview\", \"stable\", \"text-bison@001/answer_gen/v1\", \"text-bison@002/answer_gen/v1\", \"gemini-1.0-pro-001/answer_gen/v1\", \"gemini-1.0-pro-002/answer_gen/v1\", \"gemini-1.5-pro-001/answer_gen/v1\"] {allow-input: true}\n",
        "\n",
        "    resp = requests.post(\n",
        "      f'https://discoveryengine.googleapis.com/v1alpha/projects/{project_id}/locations/{location_id}/collections/default_collection/dataStores/{datastore_id}/servingConfigs/default_search:answer',\n",
        "      headers={\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': 'Bearer ' + auth_token,\n",
        "      },\n",
        "      json={\n",
        "    \"query\": { \"text\": query_input},\n",
        "\n",
        "        # Return Related / Followup questions if set to True.\n",
        "        \"relatedQuestionsSpec\": {\n",
        "            \"enable\": related_questions,\n",
        "        },\n",
        "\n",
        "\n",
        "        \"queryUnderstandingSpec\": {\n",
        "          # Query rephraser that transfer the raw query to\n",
        "          # 1. shorter search query\n",
        "          # 2. multiple queries\n",
        "          # 3. multi-steps queries (that could run search multi-times based on search results)\n",
        "          \"queryRephraserSpec\": {\n",
        "              \"disable\": disable_query_rephraser, # disable the rephraser\n",
        "              \"maxRephraseSteps\": max_rephrase_steps,\n",
        "          },\n",
        "        },\n",
        "\n",
        "\n",
        "        \"searchSpec\": {\n",
        "            \"searchParams\": {\n",
        "                # Max search results to return by search.\n",
        "                \"maxReturnResults\": max_return_results,\n",
        "                # same as search API\n",
        "                \"filter\": search_filter,\n",
        "            },\n",
        "        },\n",
        "\n",
        "\n",
        "        \"answerGenerationSpec\": {\n",
        "          # enable the citations in the output\n",
        "          \"includeCitations\": include_citations,\n",
        "\n",
        "          # force the answer to be generated in a target language.\n",
        "          \"answerLanguageCode\": answer_gen_language_code,\n",
        "\n",
        "          \"modelSpec\": {\n",
        "              # A couple options for the model: https://cloud.google.com/generative-ai-app-builder/docs/answer-generation-models\n",
        "              \"modelVersion\": answer_gen_version,\n",
        "          },\n",
        "\n",
        "          # Customer preamble that could be put in the LLM input.\n",
        "          # Example Preamble to test\n",
        "          # Given the conversation between a user and a helpful assistant and some search results, create a final answer for the assistant.\n",
        "          # The answer should use all relevant information from the search results, not introduce any additional information,\n",
        "          # and use exactly the same words as the search results when possible. The assistantâ€™s answer should be no more than 20 sentences.\n",
        "          # The user is an expert who has an in-depth understanding of the subject matter.\n",
        "          # The assistant should answer in a technical manner that uses specialized knowledge and terminology when it helps answer the query.\n",
        "          \"promptSpec\":{ \"preamble\": answer_gen_preamble },\n",
        "\n",
        "          # Do not generate answer for adversarial queries\n",
        "          \"ignoreAdversarialQuery\": ignore_adversarial_query,\n",
        "\n",
        "          # Do not generate answer for non-answer seeking queries\n",
        "          \"ignoreNonAnswerSeekingQuery\": ignore_non_answer_seeking_query,\n",
        "        },\n",
        "\n",
        "        \"safetySpec\": {\n",
        "            \"enable\": safe_search,\n",
        "        },\n",
        "\n",
        "        \"asynchronousMode\": asynchronous_mode,\n",
        "      },\n",
        "    )\n",
        "    return resp.json()"
      ],
      "metadata": {
        "id": "bxnn1yucnvS5"
      },
      "id": "bxnn1yucnvS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_search_tool_response(response):\n",
        "  # check if tool has a answer in the response\n",
        "  if \"answer\" in response:\n",
        "    answer_object = response[\"answer\"]\n",
        "    print(answer_object.keys())\n",
        "    # successful retrieval\n",
        "    if \"state\" in answer_object and answer_object[\"state\"] == \"SUCCEEDED\":\n",
        "      answerText = answer_object[\"answerText\"]\n",
        "      citations = answer_object[\"citations\"]\n",
        "      references = answer_object[\"references\"]\n",
        "      related_questions = answer_object[\"relatedQuestions\"]\n",
        "      print(answerText)"
      ],
      "metadata": {
        "id": "-uOZxYRqoMh3"
      },
      "id": "-uOZxYRqoMh3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCP Search image tool"
      ],
      "metadata": {
        "id": "jMnYWPNQoaW0"
      },
      "id": "jMnYWPNQoaW0"
    },
    {
      "cell_type": "code",
      "source": [
        "def gcp_webImageSearch(\n",
        "    query_input: str,\n",
        "    auth_token: str,\n",
        "    project_id:str,\n",
        "    location_id: str,\n",
        "    app_id: str,\n",
        "    summary_result_size:int\n",
        "):\n",
        "    \"\"\"Looks up for images related to the query input in the TM Forum web pages\"\"\"\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    END_POINT_URL = f'https://discoveryengine.googleapis.com/v1/projects/{project_id}/locations/{location_id}/collections/default_collection/engines/{app_id}/servingConfigs/default_config:search'\n",
        "    headers = {'Content-type': 'application/json',\n",
        "               'Authorization':f'Bearer {auth_token}',\n",
        "               'X-Goog-User-Project': f'{project_id}'}\n",
        "    data = {\n",
        "      \"servingConfig\": f'projects/{project_id}/locations/{location_id}/collections/default_collection/engines/{app_id}/servingConfigs/default_search',\n",
        "      \"query\": f'{query_input}',\n",
        "      \"pageSize\": summary_result_size,\n",
        "      \"params\": {\"search_type\": 1}\n",
        "    }\n",
        "\n",
        "    r = requests.post(END_POINT_URL, data=json.dumps(data), headers=headers)\n",
        "    return r.json()"
      ],
      "metadata": {
        "id": "2xL4LfEnohfx"
      },
      "id": "2xL4LfEnohfx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "credentials, _ = google.auth.default()\n",
        "request = google.auth.transport.requests.Request()\n",
        "credentials.refresh(request)\n",
        "\n",
        "res = gcp_webImageSearch(\n",
        "  query_input=\"what is ODF?\",\n",
        "   auth_token=credentials.token,\n",
        "   project_id=PROJECT_ID,\n",
        "   location_id=SEARCH_APP_LOCATION,\n",
        "   app_id=DATA_STORE_ID_WEB,\n",
        "   summary_result_size= 3,\n",
        " )\n",
        "\n",
        "# pprint.pprint(res['results'][0]['document']['derivedStructData']['image']['contextLink'])\n",
        "# pprint.pprint(res)"
      ],
      "metadata": {
        "id": "Splm-27yokhD"
      },
      "id": "Splm-27yokhD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web_and_pdf(\n",
        "    query_str: str):\n",
        "\n",
        "    \"\"\"This is the function to call to answer all the user questions EXCEPT code generation requests.\"\"\"\n",
        "\n",
        "    import os\n",
        "    import requests\n",
        "    import google.auth\n",
        "    from dotenv import load_dotenv, find_dotenv\n",
        "    from google.oauth2 import service_account\n",
        "    from vertexai.generative_models import (\n",
        "      GenerativeModel,\n",
        "    )\n",
        "\n",
        "    _=load_dotenv(find_dotenv())\n",
        "\n",
        "\n",
        "    credentials, _ = google.auth.default()\n",
        "    request = google.auth.transport.requests.Request() # User is handling it, user token will come, if the service account token will come.\n",
        "    credentials.refresh(request)\n",
        "    PROJECT_ID = os.getenv('PROJECT_ID') if os.getenv('PROJECT_ID') else 'enterprise-search-gen-ai'\n",
        "    SEARCH_APP_LOCATION = os.getenv('SEARCH_APP_LOCATION') if os.getenv('SEARCH_APP_LOCATION') else 'global'\n",
        "    AGENT_LOCATION = os.getenv('AGENT_LOCATION') if os.getenv('AGENT_LOCATION') else 'us-central1'\n",
        "    DATA_STORE_ID_PDF = DATA_STORE_ID_PDF = os.getenv('DATA_STORE_ID_PDF') if os.getenv('DATA_STORE_ID_PDF') else \"tmf-metadata-layout-p_1715009821486\" # pdf\n",
        "    DATA_STORE_ID_WEB = os.getenv('DATA_STORE_ID_WEB') if os.getenv('DATA_STORE_ID_WEB') else \"tmf-public_1692445422672\" # WEB\n",
        "    SEARCH_APP_LLM_MODEL = 'gemini-1.0-pro-002/answer_gen/v1'\n",
        "\n",
        "    print(\"PROJECT_ID\", PROJECT_ID)\n",
        "\n",
        "    query = query_str\n",
        "\n",
        "    vertexai.init(project=PROJECT_ID, location=AGENT_LOCATION)\n",
        "\n",
        "    pdf_response = search_data_store(\n",
        "                  query_input=query_str,\n",
        "                  auth_token=credentials.token,\n",
        "                  project_id=PROJECT_ID,\n",
        "                  location_id=SEARCH_APP_LOCATION,\n",
        "                  datastore_id=DATA_STORE_ID_PDF,\n",
        "                  page_size= 5,\n",
        "                  llm_model_version=SEARCH_APP_LLM_MODEL\n",
        "                )\n",
        "\n",
        "    web_response = search_data_store(\n",
        "                  query_input=query_str,\n",
        "                  auth_token=credentials.token,\n",
        "                  project_id=PROJECT_ID,\n",
        "                  location_id=SEARCH_APP_LOCATION,\n",
        "                  datastore_id=DATA_STORE_ID_WEB,\n",
        "                  page_size= 5,\n",
        "                  #summary_result_size= 5,\n",
        "                  llm_model_version=SEARCH_APP_LLM_MODEL\n",
        "                )\n",
        "\n",
        "    image_response = gcp_webImageSearch(\n",
        "                              query_input=query_str,\n",
        "                              auth_token=credentials.token,\n",
        "                              project_id=PROJECT_ID,\n",
        "                              location_id=SEARCH_APP_LOCATION,\n",
        "                              app_id=DATA_STORE_ID_WEB,\n",
        "                              summary_result_size= 3,\n",
        "                      )\n",
        "\n",
        "    consolidated_responses = [pdf_response, web_response, image_response]\n",
        "    return consolidated_responses"
      ],
      "metadata": {
        "id": "jQjal0Wdotxi"
      },
      "id": "jQjal0Wdotxi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Swagger based Code generation tool for Open API specifications"
      ],
      "metadata": {
        "id": "9ExXmvEcpE-X"
      },
      "id": "9ExXmvEcpE-X"
    },
    {
      "cell_type": "code",
      "source": [
        "def swagger_gen(\n",
        "    text: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Generates servers or clients code in the language requested for the JSON spec stored in swaggerUrl and writes it to the output file\n",
        "    \"\"\"\n",
        "    import requests\n",
        "    import json\n",
        "    import google.auth.transport.requests\n",
        "    import google.oauth2.id_token\n",
        "\n",
        "    _=load_dotenv(find_dotenv())\n",
        "    CODE_GEN_CLOUD_FUNCTION_URL = os.getenv('CODE_GEN_CLOUD_FUNCTION_URL') if os.getenv('CODE_GEN_CLOUD_FUNCTION_URL') else \"https://us-central1-enterprise-search-gen-ai.cloudfunctions.net/swagger-code-generator-1\"\n",
        "\n",
        "    # credentials, _ = google.auth.default()\n",
        "    auth_request = google.auth.transport.requests.Request() # User is handling it, user token will come, if the service account token will come.\n",
        "    id_token = google.oauth2.id_token.fetch_id_token(auth_request, CODE_GEN_CLOUD_FUNCTION_URL)\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"bearer {id_token}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"text\": text\n",
        "    }\n",
        "\n",
        "    response = requests.post(CODE_GEN_CLOUD_FUNCTION_URL, headers=headers, json=data, timeout=70)\n",
        "\n",
        "    return response.json()"
      ],
      "metadata": {
        "id": "zooF1M9ko2x7"
      },
      "id": "zooF1M9ko2x7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# res = swagger_gen(\"Can you give me the code for Product catalogue management version 4?\")\n",
        "# print(res)\n",
        "# print(CODE_GEN_CLOUD_FUNCTION_URL)"
      ],
      "metadata": {
        "id": "Cwr-CebvpI8Q",
        "collapsed": true
      },
      "id": "Cwr-CebvpI8Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat History"
      ],
      "metadata": {
        "id": "VNR6Pf27pO6E"
      },
      "id": "VNR6Pf27pO6E"
    },
    {
      "cell_type": "code",
      "source": [
        "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
        "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
        "\n",
        "    messages: List[BaseMessage] = Field(default_factory=list)\n",
        "\n",
        "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
        "        \"\"\"Add a list of messages to the store\"\"\"\n",
        "        self.messages.extend(messages)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        self.messages = []\n",
        "\n",
        "# Here we use a global variable to store the chat message history.\n",
        "# This will make it easier to inspect it to see the underlying results.\n",
        "store = {}\n",
        "\n",
        "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryHistory()\n",
        "    return store[session_id]\n"
      ],
      "metadata": {
        "id": "r1QD_VLgpKwA"
      },
      "id": "r1QD_VLgpKwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create/Deploy/Redeployment Reasoning Agent"
      ],
      "metadata": {
        "id": "D22j67OgpUYm"
      },
      "id": "D22j67OgpUYm"
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=PROJECT_ID, location=AGENT_LOCATION, staging_bucket=STAGING_BUCKET)"
      ],
      "metadata": {
        "id": "xGOj32NvpRQr"
      },
      "id": "xGOj32NvpRQr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## This prompt template needs to be changed\n",
        "# prompt = {\n",
        "#     \"input\": lambda x: x[\"input\"],\n",
        "#     \"agent_scratchpad\": (\n",
        "#         lambda x: format_to_openai_function_messages(x[\"intermediate_steps\"])\n",
        "#     ),\n",
        "# } | prompts.ChatPromptTemplate.from_messages([\n",
        "#     (\"system\", \"\"\"\n",
        "#     - Greet the users and then ask how you can help them today.\n",
        "#     - You are an expert TM Forum assistant, to help people with TMForum related documentation and specifications which are available in the form of PDF and web assets.\n",
        "#     - Call search_web_and_pdf whenever you are asked about some information about TM Forum organisation. Please answer the user query from all the relevant information conatained in any part of the context. Please provide detailed responses. Please add the citations in the context, in the format of [#], where # is a number, to the summary at the appropriate place. Ensure that the citation numbers you add to the summary match the citation numbers in the context.\n",
        "#     - Call swagger_gen whenever you are asked to generate server or client code or any code for any open api specification.\n",
        "#     Example:\n",
        "#     'The code for Product catalogue management version 4 is available at https://storage.cloud.google.com/tfm-ai-assistant-codegen-dev/generatedCodeFile/TMF620_Product_Catalog_Management_API_v4_1716933037458.zip.'\n",
        "#     - If necessary, seek clarifying details, Please do not make up any information.\n",
        "#     - Please restrict yourself to the information related to TM Forum.\n",
        "#     \"\"\"),\n",
        "#     (\"user\", \"{input}\"),\n",
        "#     (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "# ])"
      ],
      "metadata": {
        "id": "k-e57wI6qTso"
      },
      "id": "k-e57wI6qTso",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DISPLAY_NAME = \"TMFMultiChatAppJune05v1\"\n",
        "remote_app = reasoning_engines.ReasoningEngine.create(\n",
        "    reasoning_engines.LangchainAgent(\n",
        "        # prompt=prompt,\n",
        "        model=AGENT_LLM_MODEL,\n",
        "        tools=[search_web_and_pdf,swagger_gen],\n",
        "        model_kwargs=AGENT_LLM_MODEL_KWARGS,\n",
        "        agent_executor_kwargs={\"return_intermediate_steps\": True},\n",
        "    ),\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform==1.51.0\",\n",
        "        \"langchain==0.1.20\",\n",
        "        \"langchain-google-vertexai==1.0.3\",\n",
        "        \"cloudpickle==3.0.0\",\n",
        "        \"pydantic==2.7.1\",\n",
        "        \"requests\",\n",
        "        # \"google-cloud-discoveryengine\",\n",
        "        \"google-auth\",\n",
        "        \"python-dotenv\"\n",
        "    ],\n",
        "    display_name=DISPLAY_NAME,\n",
        ")\n",
        "remote_app"
      ],
      "metadata": {
        "id": "_He31t_jpTtq"
      },
      "id": "_He31t_jpTtq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "try:\n",
        "  res = remote_app.query(input=\"Describe ODF?\")\n",
        "  pprint.pprint(res)\n",
        "except Exception as e:\n",
        "   pprint.pprint(e)"
      ],
      "metadata": {
        "id": "aTQGHgW-ulH0",
        "collapsed": true
      },
      "id": "aTQGHgW-ulH0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Reasoning Engine"
      ],
      "metadata": {
        "id": "ueX2qXRmcjIb"
      },
      "id": "ueX2qXRmcjIb"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "import json\n",
        "import requests\n",
        "\n",
        "def call_tmf_aiva_agent(query_str, token, url):\n",
        "  \"\"\"Makes a POST request to the specified Reasoning Engine endpoint.\"\"\"\n",
        "  # Set the headers and data\n",
        "  headers = {\n",
        "    \"Authorization\": f\"Bearer {token}\",\n",
        "    \"Content-Type\": \"application/json; charset=utf-8\",\n",
        "  }\n",
        "\n",
        "  # Create the JSON payload from the query_str\n",
        "  json_input = {\"input\": {\"input\": f\"{query_str}\"}}\n",
        "\n",
        "  # Send the POST request\n",
        "  r = requests.post(url, headers=headers, data=json.dumps(json_input))\n",
        "  return r.json()"
      ],
      "metadata": {
        "id": "oCa4ZjSuulq1"
      },
      "id": "oCa4ZjSuulq1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credentials, _ = google.auth.default()\n",
        "request = google.auth.transport.requests.Request()\n",
        "credentials.refresh(request)\n",
        "token = credentials.token"
      ],
      "metadata": {
        "id": "MD5srImyclr9"
      },
      "id": "MD5srImyclr9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Describe ODF\",\n",
        "    \"Can you give me the code for Product catalogue management version 4? use swagger gen tool\",\n",
        "    \"Are TM Forum and MEF APIs the same?\"\n",
        "]\n",
        "url = \"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/982845833565/locations/us-central1/reasoningEngines/4637335425680146432:query\""
      ],
      "metadata": {
        "id": "9T1P_tbocn3G"
      },
      "id": "9T1P_tbocn3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = call_tmf_aiva_agent(queries[0], token, url)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "qFrDgCGkcqCF"
      },
      "id": "qFrDgCGkcqCF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Un-deployment of Reasoning Engine"
      ],
      "metadata": {
        "id": "SuY16QdwcuM0"
      },
      "id": "SuY16QdwcuM0"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import vertexai\n",
        "from vertexai.preview import reasoning_engines"
      ],
      "metadata": {
        "id": "aR69kOOrcrzO"
      },
      "id": "aR69kOOrcrzO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_reasoning_engine(project_id, location, engine, rate_limit_time=30):\n",
        "  try:\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "    reasoning_engine = reasoning_engines.ReasoningEngine(engine)\n",
        "    reasoning_engine.delete()\n",
        "    time.sleep(rate_limit_time)\n",
        "    return True\n",
        "  except Exception as exc:\n",
        "    return False"
      ],
      "metadata": {
        "id": "kDeTRcZucyyg"
      },
      "id": "kDeTRcZucyyg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# engine to delete\n",
        "_=load_dotenv(find_dotenv())\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID') if os.getenv('PROJECT_ID') else '982845833565'\n",
        "LOCATION = os.getenv('AGENT_LOCATION') if os.getenv('AGENT_LOCATION') else 'us-central1'\n",
        "REASONING_ENGINE_ID = \"931998832261070848\" # this has to be manually updated from the deployment section output!!!"
      ],
      "metadata": {
        "id": "u2tLB8xac1AS"
      },
      "id": "u2tLB8xac1AS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status = delete_reasoning_engine(PROJECT_ID, LOCATION, REASONING_ENGINE_ID)\n",
        "print(status)"
      ],
      "metadata": {
        "id": "Zqw347LQc3Fx"
      },
      "id": "Zqw347LQc3Fx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing existing reasoning engines"
      ],
      "metadata": {
        "id": "rlgZLYCLCm3R"
      },
      "id": "rlgZLYCLCm3R"
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview import reasoning_engines"
      ],
      "metadata": {
        "id": "LESYLqCILErV"
      },
      "id": "LESYLqCILErV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_=load_dotenv(find_dotenv())\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID') if os.getenv('PROJECT_ID') else '982845833565'\n",
        "LOCATION = os.getenv('AGENT_LOCATION') if os.getenv('AGENT_LOCATION') else 'us-central1'\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "# list reasoning engines\n",
        "reasoning_engine_list = reasoning_engines.ReasoningEngine.list()\n",
        "print(reasoning_engine_list)"
      ],
      "metadata": {
        "id": "-UtxTs1eCtmm"
      },
      "id": "-UtxTs1eCtmm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1zog7srICqb"
      },
      "id": "W1zog7srICqb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "reasoningEngineCodeRefactorGithubv4.ipynb",
      "private_outputs": true,
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}