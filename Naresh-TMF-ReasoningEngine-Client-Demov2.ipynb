{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TMF Guru demo"
      ],
      "metadata": {
        "id": "aPDHKad4SHPI"
      },
      "id": "aPDHKad4SHPI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "OrnezaWQSLiS"
      },
      "id": "OrnezaWQSLiS"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ratelimit ratelimiter python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvzmnfO2SHnh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603279578,
          "user_tz": -330,
          "elapsed": 8314,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "65bf808d-3b58-40e8-fb3d-5e59ae72b0d2"
      },
      "id": "IvzmnfO2SHnh",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ratelimit in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: ratelimiter in /usr/local/lib/python3.10/dist-packages (1.2.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ratelimiter import RateLimiter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sl8QhiUST_SC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603285219,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "sl8QhiUST_SC",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Variables"
      ],
      "metadata": {
        "id": "UGspcQ0ySU_j"
      },
      "id": "UGspcQ0ySU_j"
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "PROJECT_ID = os.getenv('PROJECT_ID')\n",
        "LOCATION = os.getenv('AGENT_LOCATION') # \"global\" # \"us-central1\"\n",
        "REASONING_ENGINE_ID = \"6186010747542175744\"\n"
      ],
      "metadata": {
        "id": "0cnl8js6SRuF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603288556,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "0cnl8js6SRuF",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TMF AVIA - Response parser boiler plate\n"
      ],
      "metadata": {
        "id": "Iy6CNTb2S4y8"
      },
      "id": "Iy6CNTb2S4y8"
    },
    {
      "cell_type": "code",
      "source": [
        "# doc_type values - pdf / web\n",
        "def parse_search_tool_response(response, doc_type=\"pdf\"):\n",
        "  tool_response = {}\n",
        "  # check if tool has a answer in the response\n",
        "  if \"answer\" in response:\n",
        "    answer_object = response[\"answer\"]\n",
        "    # print(answer_object.keys())\n",
        "    # successful retrieval\n",
        "    if \"state\" in answer_object and answer_object[\"state\"] == \"SUCCEEDED\":\n",
        "      answerText = answer_object[\"answerText\"] if \"answerText\" in answer_object else \"\"\n",
        "      # citations = answer_object[\"citations\"] if \"citations\" in answer_object else []\n",
        "      # parse references\n",
        "      references = []\n",
        "      references_raw_list = answer_object[\"references\"] if \"references\" in answer_object else []\n",
        "      for ref in references_raw_list:\n",
        "        chunk_info = ref[\"chunkInfo\"] if \"chunkInfo\" in ref else  \"\"\n",
        "        if \"\" != chunk_info and \"documentMetadata\" in chunk_info:\n",
        "          document_metadata = chunk_info[\"documentMetadata\"]\n",
        "          reference = {}\n",
        "          title = document_metadata[\"title\"] if \"title\" in document_metadata else \"\"\n",
        "          # TODO change uri from gs:// to http://\n",
        "          uri = document_metadata[\"uri\"] if \"uri\" in document_metadata else \"\"\n",
        "          reference[\"title\"] = title\n",
        "          reference[\"uri\"] = uri\n",
        "          docId = \"\"\n",
        "          if doc_type == \"pdf\":\n",
        "            if \"structData\" in document_metadata:\n",
        "              struct_data = document_metadata[\"structData\"]\n",
        "              docId = document_metadata[\"structData\"][\"DocId\"] if \"DocId\" in document_metadata[\"structData\"] else \"\"\n",
        "              reference[\"docId\"] = docId\n",
        "          references.append(reference)\n",
        "\n",
        "      related_questions = answer_object[\"relatedQuestions\"] if \"relatedQuestions\" in answer_object else []\n",
        "      tool_response = {\n",
        "        \"answerText\": answerText,\n",
        "        \"references\": references,\n",
        "        \"related_questions\": related_questions\n",
        "      }\n",
        "    return tool_response\n",
        "\n",
        "\n",
        "def parse_agent_response(response):\n",
        "  formated_agent_respone = {}\n",
        "  if \"output\" in response:\n",
        "    agent_output_response = response[\"output\"]\n",
        "    is_codegen = False\n",
        "    formated_agent_respone[\"input\"] = agent_output_response[\"input\"]\n",
        "    formated_agent_respone[\"output\"] = agent_output_response[\"output\"]\n",
        "    # hacky solution\n",
        "    if \".zip\" in agent_output_response[\"output\"]:\n",
        "      is_codegen = True\n",
        "    if \"intermediate_steps\" in agent_output_response:\n",
        "      intermediate_steps = agent_output_response[\"intermediate_steps\"]\n",
        "      if len(intermediate_steps) > 0:\n",
        "        intermediate_steps = intermediate_steps[0]\n",
        "        if len(intermediate_steps) == 2:\n",
        "          tool_responses = intermediate_steps[1]\n",
        "          if len(tool_responses) == 3:\n",
        "            pdf_response = tool_responses[0]\n",
        "            web_response = tool_responses[1]\n",
        "            image_response = tool_responses[2]\n",
        "            # parse pdf and web search tool response\n",
        "            pdf_response_json = parse_search_tool_response(pdf_response, doc_type=\"pdf\")\n",
        "            web_response_json = parse_search_tool_response(web_response, doc_type=\"web\")\n",
        "            # parse image search tool response\n",
        "            image_response_json = {}\n",
        "            if \"summary\" in image_response:\n",
        "              if image_response[\"summary\"] != \"\":\n",
        "                image_summary = image_response[\"summary\"]\n",
        "                image_response_json[\"summary\"] = image_summary\n",
        "\n",
        "            image_docs = []\n",
        "            if \"results\" in image_response:\n",
        "              if len(image_response[\"results\"]) > 0:\n",
        "                for image_doc in image_response[\"results\"]:\n",
        "                  if \"document\" in image_doc:\n",
        "                    if \"derivedStructData\" in image_doc[\"document\"]:\n",
        "                      title = image_doc[\"document\"][\"derivedStructData\"][\"title\"]\n",
        "                      link = image_doc[\"document\"][\"derivedStructData\"][\"link\"]\n",
        "                      image_metadata = image_doc[\"document\"][\"derivedStructData\"][\"image\"]\n",
        "                      context_link = image_metadata[\"contextLink\"]\n",
        "                      image = {}\n",
        "                      image[\"title\"] = title\n",
        "                      image[\"link\"] = link\n",
        "                      image[\"contextLink\"] = context_link\n",
        "                      image_docs.append(image)\n",
        "                image_response_json[\"images\"] = image_docs\n",
        "\n",
        "            formated_agent_respone[\"pdf\"] = pdf_response_json\n",
        "            formated_agent_respone[\"web\"] = web_response_json\n",
        "            formated_agent_respone[\"image\"] = image_response_json\n",
        "          elif len(tool_responses) == 1:\n",
        "            code_gen_response = tool_responses\n",
        "            if \"result\" in tool_responses:\n",
        "              code_gen_response = tool_responses[\"result\"]\n",
        "              formated_agent_respone[\"code\"] = code_gen_response\n",
        "          else:\n",
        "            print(\"no of tool response: \", len(tool_responses))\n",
        "  return formated_agent_respone\n",
        "\n",
        "def build_agent_response_dict(formatted_agent_response):\n",
        "  agent_response_dict = {}\n",
        "  if \"pdf\" in formatted_agent_response:\n",
        "    agent_response_dict[\"pdf search summary\"] = formatted_agent_response[\"pdf\"][\"answerText\"]\n",
        "    # agent_response_dict[\"pdf citations\"] = formatted_agent_response[\"pdf\"][\"citations\"]\n",
        "    agent_response_dict[\"pdf references\"] = formatted_agent_response[\"pdf\"][\"references\"]\n",
        "  else:\n",
        "    agent_response_dict[\"pdf search summary\"] = \"\"\n",
        "    # agent_response_dict[\"pdf citations\"] = []\n",
        "    agent_response_dict[\"pdf references\"] = []\n",
        "\n",
        "  if \"web\" in formatted_agent_response:\n",
        "    agent_response_dict[\"web search summary\"] = formatted_agent_response[\"web\"][\"answerText\"]\n",
        "    # agent_response_dict[\"web citations\"] = formatted_agent_response[\"web\"][\"citations\"]\n",
        "    agent_response_dict[\"web references\"] = formatted_agent_response[\"web\"][\"references\"]\n",
        "  else:\n",
        "    agent_response_dict[\"web search summary\"] = \"\"\n",
        "    # agent_response_dict[\"web citations\"] = []\n",
        "    agent_response_dict[\"web references\"] = []\n",
        "\n",
        "  if \"image\" in formatted_agent_response:\n",
        "    agent_response_dict[\"images\"] = formatted_agent_response[\"image\"][\"images\"] if \"image\" in formatted_agent_response and \"images\" in formatted_agent_response[\"image\"] else []\n",
        "  else:\n",
        "    agent_response_dict[\"images\"] = []\n",
        "\n",
        "  if \"code\" in formatted_agent_response:\n",
        "    agent_response_dict[\"code\"] = formatted_agent_response[\"code\"] if \"code\" in formatted_agent_response else \"\"\n",
        "  else:\n",
        "    agent_response_dict[\"code\"] = \"\"\n",
        "\n",
        "  agent_response_dict[\"agent summary\"] = formatted_agent_response[\"output\"] if \"output\" in formatted_agent_response else \"\"\n",
        "  agent_response_dict[\"input\"] = formatted_agent_response[\"input\"] if \"input\" in formatted_agent_response else \"\"\n",
        "  return agent_response_dict\n"
      ],
      "metadata": {
        "id": "UYEC0wevS9O2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603292685,
          "user_tz": -330,
          "elapsed": 678,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "UYEC0wevS9O2",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TMF AVIA - Curl client python example"
      ],
      "metadata": {
        "id": "SKxCfXkvSgPT"
      },
      "id": "SKxCfXkvSgPT"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "import json\n",
        "import requests\n",
        "\n",
        "def call_tmf_aiva_agent(query_str, token):\n",
        "  \"\"\"Makes a POST request to the specified Reasoning Engine endpoint.\"\"\"\n",
        "  # Set the headers and data\n",
        "  headers = {\n",
        "    \"Authorization\": f\"Bearer {token}\",\n",
        "    \"Content-Type\": \"application/json; charset=utf-8\",\n",
        "  }\n",
        "\n",
        "  # Create the JSON payload from the query_str\n",
        "  json_input = {\"input\": {\"input\": f\"{query_str}\"}}\n",
        "\n",
        "  # Construct the URL\n",
        "  _=load_dotenv(find_dotenv())\n",
        "\n",
        "  PROJECT_ID = os.getenv('PROJECT_ID_INT') if os.getenv('PROJECT_ID_INT') else '982845833565'\n",
        "  LOCATION_ID = os.getenv('AGENT_LOCATION') if os.getenv('AGENT_LOCATION') else 'us-central1'\n",
        "\n",
        "  REASONING_ENGINE_ID = os.getenv('REASONING_ENGINE_ID') if os.getenv('REASONING_ENGINE_ID') else \"6866054291275120640\"\n",
        "  url = f\"https://{LOCATION_ID}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION_ID}/reasoningEngines/{REASONING_ENGINE_ID}:query\"\n",
        "\n",
        "  # Send the POST request\n",
        "  r = requests.post(url, headers=headers, data=json.dumps(json_input))\n",
        "  return r.json()"
      ],
      "metadata": {
        "id": "i11U_4hYSX4_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603330992,
          "user_tz": -330,
          "elapsed": 672,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "i11U_4hYSX4_",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TMF AIVA - Adhoc Testing"
      ],
      "metadata": {
        "id": "Fd-G5ajqGBps"
      },
      "id": "Fd-G5ajqGBps"
    },
    {
      "cell_type": "code",
      "source": [
        "credentials, _ = google.auth.default()\n",
        "request = google.auth.transport.requests.Request()\n",
        "credentials.refresh(request)\n",
        "token = credentials.token"
      ],
      "metadata": {
        "id": "-331BHgQUsii",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603338018,
          "user_tz": -330,
          "elapsed": 654,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "-331BHgQUsii",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Describe ODF\",\n",
        "    \"Can you give me the code for Product catalogue management version 4? use swagger gen tool\",\n",
        "    \"Are TM Forum and MEF APIs the same?\"\n",
        "]"
      ],
      "metadata": {
        "id": "sVbyTkfmwiga",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603342014,
          "user_tz": -330,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "sVbyTkfmwiga",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "experiment = \"June05Adhoc\"\n",
        "batch = \"v1\"\n",
        "bucket_name = \"tmf_input_files\"\n",
        "source_file_name = \"bulk_question_answering_reasoning_engine_summary.csv\"\n",
        "destination_file_name = f\"bulk_question_answering_reasoning_engine_summary_result{experiment}_{batch}.csv\"\n",
        "\n",
        "def adhoc_testing(query, token, search_type=\"search\"): # search_type = search | code_gen\n",
        "  res = call_tmf_aiva_agent(queries, token)\n",
        "  formatted_agent_response = parse_agent_response(res)\n",
        "  with open(f'reasoning_agent_{search_type}_response.json', 'w') as fp:\n",
        "    json.dump(res, fp)\n",
        "\n",
        "  with open(f'reasoning_agent_{search_type}_formatted_response.json', 'w') as fp:\n",
        "      json.dump(formatted_agent_response, fp)\n",
        "  agent_response_dict = build_agent_response_dict(formatted_agent_response)\n",
        "  df_agent_response_dict = pd.DataFrame([agent_response_dict])\n",
        "  df_agent_response_dict.to_csv(f\"gs://{bucket_name}/{destination_file_name}\", sep=\",\", mode='a', index=False, header=True)\n"
      ],
      "metadata": {
        "id": "qQeZ0_IaldbV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603344673,
          "user_tz": -330,
          "elapsed": 0,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "qQeZ0_IaldbV",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adhoc_testing(queries[0], token, \"search\")"
      ],
      "metadata": {
        "id": "oRSpR1T8zEUV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717603437597,
          "user_tz": -330,
          "elapsed": 87975,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "oRSpR1T8zEUV",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adhoc_testing(\"What is the role of CSPs in the coming years?\", token, \"search\")"
      ],
      "metadata": {
        "id": "YDtnDd5wQKAT"
      },
      "id": "YDtnDd5wQKAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TMF AIVA - Bulk QA testing"
      ],
      "metadata": {
        "id": "lw4OzVxMKJcJ"
      },
      "id": "lw4OzVxMKJcJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "experiment = \"June05Bulk\"\n",
        "batch = \"v1\"\n",
        "bucket_name = \"tmf_input_files\"\n",
        "source_file_name = \"bulk_question_answering_reasoning_engine_summary.csv\"\n",
        "destination_file_name = f\"bulk_question_answering_reasoning_engine_summary_result{experiment}_{batch}.csv\""
      ],
      "metadata": {
        "id": "REFef8uTKE69"
      },
      "id": "REFef8uTKE69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bulk_qa():\n",
        "  df = pd.read_csv(\"gs://tmf_input_files/bulk_qa_mixed_questions.csv\", header=0, dtype=str)\n",
        "  rate_limiter = RateLimiter(max_calls=4, period=60)\n",
        "  summary_df = pd.DataFrame()\n",
        "  queries = []\n",
        "  for index, row in df.iterrows():\n",
        "    queries.append(row[\"Query\"])\n",
        "\n",
        "  random.shuffle(queries)\n",
        "  try:\n",
        "    for query in queries:\n",
        "      with rate_limiter:\n",
        "        start = time.time()\n",
        "        agent_response = call_tmf_aiva_agent(query, token)\n",
        "        agent_summary = agent_response[\"output\"]\n",
        "        response = False\n",
        "        if agent_summary != \"\":\n",
        "          response = True\n",
        "        formatted_agent_response = parse_agent_response(agent_response)\n",
        "        agent_response_dict = build_agent_response_dict(formatted_agent_response)\n",
        "        df_agent_response_dict = pd.DataFrame([agent_response_dict])\n",
        "        summary_df = pd.concat([summary_df, df_agent_response_dict], ignore_index=True)\n",
        "        end = time.time()\n",
        "        print(f\"Query: {query}, output status: {response} - latency: {end - start}\")\n",
        "    summary_df.to_csv(f\"gs://{bucket_name}/{destination_file_name}\", sep=\",\", mode='a', index=False, header=True)\n",
        "  except Exception as exc:\n",
        "    summary_df.to_csv(f\"gs://{bucket_name}/{destination_file_name}\", sep=\",\", mode='a', index=False, header=True)\n",
        "    print(exc)"
      ],
      "metadata": {
        "id": "B-0j_Q65Wtfu"
      },
      "id": "B-0j_Q65Wtfu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulk_qa()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm5abtZfLLlh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1717582406829,
          "user_tz": -330,
          "elapsed": 1026821,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7e1d8853-5911-427a-c1ed-9b338d2f3856"
      },
      "id": "sm5abtZfLLlh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: how do I start building an autonomous network? - latency: 23.26177406311035\n",
            "Query: Explain in more details how I would implement autonomous operations? - latency: 27.46544098854065\n",
            "Query: How can I use ODA patterns to abstract Network components? - latency: 22.072493314743042\n",
            "Query: How can I apply NaaS? - latency: 19.00199007987976\n",
            "Query: Generate code in java for Trouble ticket API - latency: 6.074657201766968\n",
            "Query: Generate code in java for product catalogue - latency: 6.12749457359314\n",
            "Query: How do I start building an autonomous network? - latency: 29.284558057785034\n",
            "Query: Is ODA architecture AI ready? - latency: 14.746080875396729\n",
            "Query: When is DTW Mumbai? - latency: 10.882174968719482\n",
            "Query: How do I apply AI to improve my autonomous operations? - latency: 19.565954208374023\n",
            "Query: c++ code generation  for Product Ordering API - latency: 4.985942363739014\n",
            "Query: I am trying to implement an ODA enabled architecture. How do I create a customer and set up their account? - latency: 23.933101654052734\n",
            "Query: csharp code  generation request for trouble ticket management - latency: 17.393084287643433\n",
            "Query: Describe ODF architecture? - latency: 21.958301782608032\n",
            "Query: please generate code in nodeJS for product Catalog API: NoneType object has no content - latency: 5.26441216468811\n",
            "Query: please generate code in python langauage for Trouble Ticket API - latency: 5.3471291065216064\n",
            "Query: csharp code  generation request for trouble ticket management/ With C# Error: 500 NoneType object  - latency: 3.8556671142578125\n",
            "Query: request you to please generate code  in python  for trouble ticket management  - latency: 5.459370136260986\n",
            "Query: List only the Level L3 eTOM business activities the Product Catalog Management component (TMFC001) is responsible for? - latency: 15.247399806976318\n",
            "Query: List only the Level L2 eTOM business activities that have L3 activities under them in the Product Catalog Management component (TMFC001)? - latency: 16.57764744758606\n",
            "Query: Can you generate html code for product catalog management - latency: 5.5006537437438965\n",
            "Query: Build me a plan using TM Forum ODA to deliver autonomous operations - latency: 24.165701627731323\n",
            "Query: please generate code in nodeJS for trouble ticket management  - latency: 5.119688987731934\n",
            "Query: please generate code in python langauage for Product Ordering API - latency: 20.234984874725342\n",
            "Query: Can you tell me a usecase how to slice 5G? - latency: 28.575612545013428\n",
            "Query: I am strugging to have compatible code for Product Catalog Management. Please help with code generation in any preferred language. - latency: 13.810760498046875\n",
            "Query: Can you generate html code for Product Ordering  API - latency: 20.019973278045654\n",
            "Query: How do I implement Zero trust principles to my architecture? - latency: 30.220436096191406\n",
            "Query: How do I upgrade Decision Intelligence through use of Digital Twins? - latency: 17.10758066177368\n",
            "Query: How are telecom operators planning to monetize network APIs? - latency: 19.818214178085327\n",
            "Query: How do I test my level of autonomous operations? - latency: 40.17357301712036\n",
            "Query: Which APIs should I use for managing the entire process from customer order through to network automation? - latency: 18.721036195755005\n",
            "Query: Is Autonomous Network Architecture ODA compliant? - latency: 17.93201732635498\n",
            "Query: List all the eTOM business activities the Product Catalog Management component (TMFC001) is responsible for? - latency: 19.524489402770996\n",
            "Query: please generate code in python langauage for product Catalog - latency: 5.6475701332092285\n",
            "Query: How do I transform into ODA? - latency: 21.565167903900146\n",
            "Query: How do I implements AIOps? - latency: 22.682719945907593\n",
            "Query: What companies are 'Running on ODA' or 'Ready for ODA'? - latency: 12.498731136322021\n",
            "Query: c++ code generation  for product catalog management: Line 131, content is NoneType error.  - latency: 3.828075408935547\n",
            "Query: Describe ODA Canvas? - latency: 18.929786443710327\n",
            "Query: List all the Level 1 SIT ABEs and their corresponding Level 2 SIT ABEs  in the Product Catalog Management component (TMFC001)? - latency: 14.849586486816406\n",
            "Query: What are the mandatory exposed APIs provided by the Product Catalog Management component (TMFC001)? - latency: 15.267274618148804\n",
            "Query: How does TM Forum support autonomous operations? - latency: 21.571419954299927\n",
            "Query: csharp code  generation request for product catalog management - latency: 15.04041314125061\n",
            "Query: What is intent in Autonomous networks? - latency: 17.68878173828125\n",
            "Query: I have a requrement in Product ordering to generate the code. Can you please generate in Java - latency: 16.96154546737671\n",
            "Query: request you to please generate code  in python  for product catalog management - latency: 4.995126962661743\n",
            "Query: how do I deploy the ODA canvas? - latency: 19.25545620918274\n",
            "Query: please generate code in java langauage for ticket management - latency: 5.276819944381714\n",
            "Query: Can you generate html code for Incident Management API - latency: 5.296246290206909\n",
            "Query: What is a good API for Network Circuits? - latency: 12.966439485549927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# errors faced\n",
        "\n",
        "# {'error': {'code': 400, 'message': 'Reasoning Engine Execution failed. Error Details: {\"detail\":\"Traceback (most recent call last):\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\\\\\", line 170, in error_remapped_callable\\\\n    return _StreamingResponseIterator(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\\\\\", line 92, in __init__\\\\n    self._stored_first_result = next(self._wrapped)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/grpc/_channel.py\\\\\", line 543, in __next__\\\\n    return self._next()\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/grpc/_channel.py\\\\\", line 969, in _next\\\\n    raise self\\\\ngrpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\\\\n\\\\tstatus = StatusCode.INTERNAL\\\\n\\\\tdetails = \\\\\"Internal error occurred.\\\\\"\\\\n\\\\tdebug_error_string = \\\\\"UNKNOWN:Error received from peer ipv4:173.194.196.95:443 {created_time:\\\\\"2024-06-04T12:47:56.563121229+00:00\\\\\", grpc_status:13, grpc_message:\\\\\"Internal error occurred.\\\\\"}\\\\\"\\\\n>\\\\n\\\\nThe above exception was the direct cause of the following exception:\\\\n\\\\nTraceback (most recent call last):\\\\n  File \\\\\"/code/app/api/factory/python_file_api_builder.py\\\\\", line 109, in handler\\\\n    output = invocation_callable(**invocation_payload)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/vertexai/preview/reasoning_engines/templates/langchain.py\\\\\", line 399, in query\\\\n    self._runnable.invoke(input=input, config=config, **kwargs)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/chains/base.py\\\\\", line 163, in invoke\\\\n    raise e\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/chains/base.py\\\\\", line 153, in invoke\\\\n    self._call(inputs, run_manager=run_manager)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/agents/agent.py\\\\\", line 1432, in _call\\\\n    next_step_output = self._take_next_step(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/agents/agent.py\\\\\", line 1138, in _take_next_step\\\\n    [\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/agents/agent.py\\\\\", line 1138, in <listcomp>\\\\n    [\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/agents/agent.py\\\\\", line 1166, in _iter_next_step\\\\n    output = self.agent.plan(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain/agents/agent.py\\\\\", line 514, in plan\\\\n    for chunk in self.runnable.stream(inputs, config={\\\\\"callbacks\\\\\": callbacks}):\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 2875, in stream\\\\n    yield from self.transform(iter([input]), config, **kwargs)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 2862, in transform\\\\n    yield from self._transform_stream_with_config(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 1881, in _transform_stream_with_config\\\\n    chunk: Output = context.run(next, iterator)  # type: ignore\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 2826, in _transform\\\\n    for output in final_pipeline:\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 1282, in transform\\\\n    for ichunk in input:\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 4736, in transform\\\\n    yield from self.bound.transform(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\\\", line 1300, in transform\\\\n    yield from self.stream(final, config, **kwargs)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\\\", line 249, in stream\\\\n    raise e\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\\\", line 229, in stream\\\\n    for chunk in self._stream(messages, stop=stop, **kwargs):\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py\\\\\", line 758, in _stream\\\\n    for response_chunk in response_iter:\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py\\\\\", line 572, in _generate_content_streaming\\\\n    response_stream = self._prediction_client.stream_generate_content(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py\\\\\", line 2228, in stream_generate_content\\\\n    response = rpc(\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\\\\\", line 131, in __call__\\\\n    return wrapped_func(*args, **kwargs)\\\\n  File \\\\\"/usr/local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\\\\\", line 174, in error_remapped_callable\\\\n    raise exceptions.from_grpc_error(exc) from exc\\\\ngoogle.api_core.exceptions.InternalServerError: 500 Internal error occurred.\\\\n\"}', 'status': 'FAILED_PRECONDITION'}}\n"
      ],
      "metadata": {
        "id": "DoSH4BYR0npY"
      },
      "id": "DoSH4BYR0npY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JGtntFnSBljH"
      },
      "id": "JGtntFnSBljH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "Naresh-TMF-ReasoningEngine-Client-Demov2.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}